{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_MONTH = '2015_05_28'\n",
    "TEST_MONTH = '2016_05_28'\n",
    "\n",
    "TRAIN_FILE = 'data/train_' + TRAIN_MONTH + '.csv'\n",
    "ADDED_PRODUCTS_FILE = 'data/added_product_' + TRAIN_MONTH + '.csv'\n",
    "\n",
    "TEST_FILE = 'data/train_' + TEST_MONTH + '.csv'\n",
    "\n",
    "HEADER = [\"fecha_dato\", \"ncodpers\", \"ind_empleado\",\n",
    "          \"pais_residencia\", \"sexo\", \"age\", \"fecha_alta\",\n",
    "          \"ind_nuevo\", \"antiguedad\", \"indrel\", \"ult_fec_cli_1t\",\n",
    "          \"indrel_1mes\", \"tiprel_1mes\", \"indresi\", \"indext\",\n",
    "          \"conyuemp\", \"canal_entrada\", \"indfall\", \"tipodom\",\n",
    "          \"cod_prov\", \"nomprov\", \"ind_actividad_cliente\",\n",
    "          \"renta\", \"segmento\", \"ind_ahor_fin_ult1\",\n",
    "          \"ind_aval_fin_ult1\", \"ind_cco_fin_ult1\",\n",
    "          \"ind_cder_fin_ult1\", \"ind_cno_fin_ult1\",\n",
    "          \"ind_ctju_fin_ult1\", \"ind_ctma_fin_ult1\",\n",
    "          \"ind_ctop_fin_ult1\", \"ind_ctpp_fin_ult1\",\n",
    "          \"ind_deco_fin_ult1\", \"ind_deme_fin_ult1\",\n",
    "          \"ind_dela_fin_ult1\", \"ind_ecue_fin_ult1\",\n",
    "          \"ind_fond_fin_ult1\", \"ind_hip_fin_ult1\",\n",
    "          \"ind_plan_fin_ult1\", \"ind_pres_fin_ult1\",\n",
    "          \"ind_reca_fin_ult1\", \"ind_tjcr_fin_ult1\",\n",
    "          \"ind_valo_fin_ult1\", \"ind_viv_fin_ult1\",\n",
    "          \"ind_nomina_ult1\", \"ind_nom_pens_ult1\",\n",
    "          \"ind_recibo_ult1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2705: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2705: DtypeWarning: Columns (11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_FILE, header=None, names=HEADER)\n",
    "test = pd.read_csv(TEST_FILE, header=None, names=HEADER)\n",
    "added_products = pd.read_csv(ADDED_PRODUCTS_FILE)\n",
    "\n",
    "combined = pd.concat((train, test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data_from_original_dataframe(combined):\n",
    "    # fixing age\n",
    "    combined['age'] = pd.to_numeric(combined['age'], errors='coerce')\n",
    "\n",
    "    combined.loc[combined.age < 18, \"age\"] = \\\n",
    "        combined.loc[(combined.age > 18) &\n",
    "                     (combined.age <= 30), \"age\"].mean(skipna=True)\n",
    "    combined.loc[combined.age > 100, \"age\"] = \\\n",
    "        combined.loc[(combined.age > 30) &\n",
    "                     (combined.age <= 100), \"age\"].mean(skipna=True)\n",
    "    combined['age'].fillna(combined['age'].mean(), inplace=True)\n",
    "    combined['age'] = combined['age'].astype(int)\n",
    "\n",
    "    # fix ind_nuevo..\n",
    "    combined.loc[combined.ind_nuevo.isnull(), 'ind_nuevo'] = 1\n",
    "\n",
    "    # fix antiguedad\n",
    "    combined['antiguedad'] = pd.to_numeric(combined['antiguedad'],\n",
    "                                           errors='coerce')\n",
    "    combined.loc[combined.antiguedad.isnull(), 'antiguedad'] = \\\n",
    "        combined.antiguedad.min()\n",
    "    combined.loc[combined.antiguedad < 0, 'antiguedad'] = 0\n",
    "\n",
    "    # fix indrel\n",
    "    combined.loc[combined.indrel.isnull(), 'indrel'] = 1\n",
    "\n",
    "    # drop useless cols\n",
    "    combined.drop(['tipodom', 'cod_prov'], axis=1, inplace=True)\n",
    "\n",
    "    # fix ind_actividad_cliente\n",
    "    combined.loc[combined.ind_actividad_cliente.isnull(),\n",
    "                 \"ind_actividad_cliente\"] = \\\n",
    "        combined.ind_actividad_cliente.median()\n",
    "\n",
    "    # fix city name\n",
    "    combined.loc[combined.nomprov ==\n",
    "                 \"CORU\\xc3\\x91A, A\", \"nomprov\"] = \"CORUNA, A\"\n",
    "    combined.loc[combined.nomprov.isnull(), 'nomprov'] = 'UNKNOWN'\n",
    "\n",
    "    # fix incomes\n",
    "    # combined.renta = pd.to_numeric(combined.renta, errors='coerce')\n",
    "    grouped = combined.groupby('nomprov').\\\n",
    "        agg({'renta': lambda x: x.median(skipna=True)}).reset_index()\n",
    "    new_incomes = pd.merge(combined, grouped,\n",
    "                           how='inner',\n",
    "                           on='nomprov').loc[:, ['nomprov', 'renta_y']]\n",
    "\n",
    "    new_incomes = new_incomes.\\\n",
    "        rename(columns={\"renta_y\": \"renta\"}).\\\n",
    "        sort_values(\"renta\").sort_values(\"nomprov\")\n",
    "\n",
    "    combined.sort_values(\"nomprov\", inplace=True)\n",
    "    combined = combined.reset_index()\n",
    "    new_incomes = new_incomes.reset_index()\n",
    "    combined.loc[combined.renta.isnull(), \"renta\"] = \\\n",
    "        new_incomes.loc[combined.renta.isnull(), \"renta\"].median()\n",
    "    combined.sort_values(by='fecha_dato', inplace=True)\n",
    "\n",
    "    # rest of the columns\n",
    "    string_data = combined.select_dtypes(include=[\"object\"])\n",
    "    missing_columns = [col for col in string_data\n",
    "                       if string_data[col].isnull().any()]\n",
    "    del string_data\n",
    "\n",
    "    combined.loc[combined.indfall.isnull(), 'indfall'] = 'N'\n",
    "    combined.loc[combined.tiprel_1mes.isnull(), 'tiprel_1mes'] = 'A'\n",
    "    combined.tiprel_1mes = combined.tiprel_1mes.astype('category')\n",
    "\n",
    "    map_dict = {\n",
    "        '1.0': '1',\n",
    "        '1': '1',\n",
    "        '3.0': '3',\n",
    "        'P': 'P',\n",
    "        3.0: '3',\n",
    "        2.0: '2',\n",
    "        '3': '3',\n",
    "        '2.0': '2',\n",
    "        '4.0': '4',\n",
    "        '4': '4',\n",
    "        '2': '2',\n",
    "        1.0: '1',\n",
    "        4.0: '4'\n",
    "    }\n",
    "\n",
    "    combined.indrel_1mes.fillna('P', inplace=True)\n",
    "    combined.indrel_1mes = combined.indrel_1mes.apply(lambda x: map_dict[x])\n",
    "    combined.indrel_1mes = combined.indrel_1mes.astype('category')\n",
    "\n",
    "    unknown_cols = [col for col in missing_columns if\n",
    "                    col not in ['indfall', 'tiprel_1mes', 'indrel_1mes']]\n",
    "    for col in unknown_cols:\n",
    "        combined.loc[combined[col].isnull(), col] = \"UNKNOWN\"\n",
    "\n",
    "    # feature cols\n",
    "    feature_cols = combined.iloc[:1, ].filter(regex=\"ind_+.*ult.*\").\\\n",
    "        columns.values\n",
    "    for col in feature_cols:\n",
    "        combined.loc[combined[col].isnull(), col] = 0\n",
    "        combined[col] = combined[col].astype(int)\n",
    "\n",
    "    del combined['ult_fec_cli_1t'], combined['fecha_alta']\n",
    "\n",
    "    encoders = []\n",
    "    for col in ['sexo', 'indrel_1mes', 'pais_residencia', 'ind_empleado',\n",
    "                'segmento', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp',\n",
    "                'canal_entrada', 'indfall', 'nomprov']:\n",
    "        temp_enc = LabelEncoder()\n",
    "        temp_enc.fit(combined[col])\n",
    "        combined[col] = temp_enc.transform(combined[col])\n",
    "        encoders.append(temp_enc)\n",
    "    return combined, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined, encoders = process_data_from_original_dataframe(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = combined.loc[combined.fecha_dato == '2015-05-28', :].reset_index(drop=True)\n",
    "test = combined.loc[combined.fecha_dato == '2016-05-28', :].reset_index(drop=True)\n",
    "\n",
    "del train['index'], test['index']\n",
    "del train['fecha_dato'], test['fecha_dato']\n",
    "\n",
    "#added_products.set_index('ncodpers', inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(added_products['added_product'])\n",
    "added_products['encoded_products'] = label_encoder.transform(added_products['added_product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression(verbose=1)\n",
    "# train.set_index('ncodpers', inplace=True)\n",
    "xTrain = train.loc[added_products.index, :]\n",
    "yTrain = added_products.loc[:, 'encoded_products']\n",
    "logistic.fit(train.loc[added_products.index, :], added_products.loc[:, 'encoded_products'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24460414420888729"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.88388596e-02,   1.22389780e-05,   1.23226542e-02,\n",
       "          5.71197460e-07,   1.46024128e-08,   2.10457137e-02,\n",
       "          7.64390653e-03,   1.33830336e-21,   2.24665410e-02,\n",
       "          1.06971050e-03,   9.09661108e-03,   9.10647868e-03,\n",
       "          1.37389017e-04,   3.02297621e-01,   9.26104628e-02,\n",
       "          2.37162201e-04,   3.43347582e-04,   6.89041060e-02,\n",
       "          1.68434847e-01,   1.99760659e-01,   5.67013746e-03,\n",
       "          9.68000644e-07],\n",
       "       [  8.28637576e-02,   1.38160245e-04,   1.28689125e-02,\n",
       "          6.13483200e-07,   1.39945123e-08,   2.44613962e-02,\n",
       "          6.93007965e-03,   1.64940317e-21,   2.24217309e-02,\n",
       "          1.55160060e-03,   8.39048407e-03,   8.70945941e-03,\n",
       "          1.37553518e-04,   2.88636274e-01,   9.21249089e-02,\n",
       "          2.35374359e-04,   3.13801654e-04,   7.08112724e-02,\n",
       "          1.62059299e-01,   2.11927563e-01,   5.36560602e-03,\n",
       "          5.21388997e-05],\n",
       "       [  9.67688740e-02,   4.18382811e-04,   1.66309329e-02,\n",
       "          2.92595614e-06,   3.45394031e-08,   1.96681829e-02,\n",
       "          7.05851956e-03,   4.65782573e-20,   1.80035754e-02,\n",
       "          1.58894941e-03,   8.66231349e-03,   7.82412669e-03,\n",
       "          1.65752519e-04,   2.46293555e-01,   1.03797071e-01,\n",
       "          2.77785107e-04,   3.83426080e-04,   7.91732685e-02,\n",
       "          1.72373753e-01,   2.15775088e-01,   4.89983707e-03,\n",
       "          2.33645726e-04],\n",
       "       [  8.49192290e-02,   4.33621750e-04,   1.28480153e-02,\n",
       "          5.13121209e-07,   1.36503439e-08,   2.57965916e-02,\n",
       "          6.10722911e-03,   1.88283959e-21,   2.28865788e-02,\n",
       "          1.82631429e-03,   8.19927235e-03,   8.43326885e-03,\n",
       "          1.19767529e-04,   2.84798743e-01,   9.02848266e-02,\n",
       "          2.22372590e-04,   2.73521701e-04,   7.12611525e-02,\n",
       "          1.59554927e-01,   2.16586124e-01,   5.07606647e-03,\n",
       "          3.71850381e-04],\n",
       "       [  8.10632945e-02,   4.67545913e-05,   1.24034837e-02,\n",
       "          4.50173051e-07,   1.55222915e-08,   2.26166451e-02,\n",
       "          6.81390551e-03,   1.91177523e-21,   2.36261124e-02,\n",
       "          1.31942072e-03,   9.12663444e-03,   8.97382902e-03,\n",
       "          1.23820604e-04,   2.98666903e-01,   9.03589805e-02,\n",
       "          2.33850306e-04,   2.97857700e-04,   6.94672311e-02,\n",
       "          1.64879241e-01,   2.04423377e-01,   5.54851357e-03,\n",
       "          9.67974843e-06]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict_proba(xTrain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931453/931453 [18:19<00:00, 847.49it/s]\n"
     ]
    }
   ],
   "source": [
    "test.set_index('ncodpers', inplace=True)\n",
    "preds = logistic.predict_proba(test)\n",
    "\n",
    "top_t_products = label_encoder.inverse_transform(np.argsort(preds, axis = 1)[:, ::-1][:, :])\n",
    "\n",
    "test['xgb_preds'] = [' '.join(x) for x in top_t_products]\n",
    "test['added_products'] = ['ind_recibo_ult1']*test.shape[0]\n",
    "\n",
    "for i in tqdm(test.index):\n",
    "    products = map(lambda x: x[0], filter(lambda x: x[1]==1, zip(HEADER[24:], test.loc[i, 'ind_ahor_fin_ult1':'ind_recibo_ult1'])))\n",
    "    pred_products = test.loc[i, 'xgb_preds'].split()\n",
    "    prod_string = ' '.join(filter(lambda x: x not in products, pred_products))\n",
    "    test.set_value(i, 'added_products', prod_string)\n",
    "\n",
    "submission = pd.read_csv('data/test_ver2.csv', usecols=[1])\n",
    "submission['added_products'] = ['ind_recibo_ult1']*submission.shape[0]\n",
    "submission.set_index('ncodpers', inplace=True)\n",
    "submission.added_products = test.loc[submission.index, 'added_products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing file\n",
      "Compression done\n",
      "Uploading submission data/submissions/4.my_first_logistic_sub_trained_on_jun_2015_only_added_users.csv.zip\n",
      "Upload done\n"
     ]
    }
   ],
   "source": [
    "from scripts.kaggle.helpers import make_submission\n",
    "filename = 'data/submissions/4.my_first_logistic_sub_trained_on_jun_2015_only_added_users.csv'\n",
    "description = 'my first logistic submission on jun 2015 only added products data, default logistic params, and original xgb features'\n",
    "submission.to_csv(filename, columns=['added_products'])\n",
    "make_submission(filename, description=description, submit=True, compress=True)\n",
    "# make_submission('data/submissions/2_bayesian_prob_products_counters_with_old_1_ignored.csv', description=\"2. based on bayesian probabilities, where probs are calculated only for prods when there is a transition from 0 to 1\", submit=True, compress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
